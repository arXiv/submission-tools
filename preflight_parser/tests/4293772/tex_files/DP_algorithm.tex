\section{DP Algorithms for Output-Feedback SLS}\label{sec:DP_algorithm} % introduce new things
% intro

In the following, we provide our DP algorithms to solve the output-feedback SLS \eqn{SLS_output_feedback} with the set of system level constraints ($\Scal$).
We first reformulate the SLS problem as a control problem, which then allows us to apply DP to derive explicit and approximation solutions efficiently. 


\iffalse
We will derive a dynamic program that solves \eqn{SLS_output_feedback}, resulting in an optimal stable control. 
First, we will reformulate the SLS problem as a control problem; then we will
show the exacty solution as well as an approximation to the algorithm which expedites the run time.
% add intro describing what we will do - roadmap (dp algorithm, approx algo)
% mention that we will approximate the algorithm
\fi

% subsection 1
\subsection{Control Problem Reformulation}
We can reformulate the SLS optimization \eqn{SLS_output_feedback} as a control problem by treating the system response $\OFqple$ as the state $\xbf$ and the input $\ubf$ of a linear system.
Accordingly, we can rewrite the cost function $g(\Pbfxx,\Pbfxy,\Pbfux,\Pbfuy)$ in terms of the state and input as $h(\xbf,\ubf)$, resulting in a state-feedback control problem. As such, we can apply DP to solve the control problem, which equivalently solves the original SLS optimization. Below, we describe the reformulation in detail.

\iffalse
%at each finite time horizon step $t$ as the input $U_t$ and state $x_t$ of a state feedback linear system. 
The cost function $g(\xx,\xy,\ux,\uy)$
can be rewritten in terms of the states and inputs, resulting in a state feedback optimization problem, which we can solve
using dymanic programming. \newline
% why it works for this problem
\fi

% discuss what U and X are earlier
Let $\Vec{A}$ be the stacked column vectors of a matrix $A$, we slightly abuse the notation to overwrite/define
\begin{align*}
x[\tau] = \mat{
x_{xx}[\tau] \\
x_{xy}[\tau] \\
x_{ux}[\tau]
}
= \mat{
\Vec{\Pxx[\tau]}\\ 
\Vec{\Pxy[\tau]}\\
\Vec{\Pux[\tau]}
}, \quad
u[\tau] = \Vec{\Puy[\tau]},
\end{align*}
and define the per-step cost $h_\tau$ to be
\begin{align*}
h_\tau(x[\tau],u[\tau]) = g_{\tau}(\Pxx[\tau],\Pxy[\tau],\Pux[\tau],\Puy[\tau]).
\end{align*}
Since we consider only FIR system response with horizon $T$, the constraint set in \eqn{SLS_output_feedback} can be written as
\begin{align*}
\Pxx[\tau + 1] =&\ \Pxx[\tau] A + \Pxy[\tau] C\\
\Pxy[\tau + 1] =&\ A \Pxy[\tau] + B \Puy[\tau]\\
\Pux[\tau + 1] =&\ \Pux[\tau] A + \Puy[\tau] C
\end{align*}
for all $\tau = 1,\dots,T - 1$, 
\begin{align*}
A \Pxx[\tau] + B \Pux[\tau] = \Pxx[\tau] A + \Pxy[\tau] C
\end{align*}
for all $\tau = 1,\dots,T$, and 
\begin{gather*}
\Pxx[0] = 0, \quad \Pxy[0] = 0, \quad \Pux[0] = 0,\\
\Pxx[1] = I, \quad \Pxy[1] = B \Puy[0], \quad \Pux[1] = \Puy[0] C
\end{gather*}
We can rewrite the above equations in terms of $x[\tau]$ and $u[\tau]$. Let $\Scal_x$ and $\Scal_u$ be sets such that if $\Phibf \in \Scal$ then $\xbf \in \Scal_x$ and $\ubf \in \Scal_u$. This reformulates \eqn{SLS_output_feedback} as 
\OptMin[reformulated_opt]{ % the subequation label is eqn:SLS_output_feedback
\sum\limits_{\tau = 0}^T h_\tau(x[\tau],u[\tau])
}{
\OptCons{
x[\tau+1] = \tdA x[\tau] + \tdB u[\tau]
}{\forall \tau = 1,..., T-1 }{of-state-dynamics}\\
\OptCons{
\tdA_{eq} x[\tau] = 0
}{\forall \tau = 1,..., T }{of-transition-constraint}\\
\OptCons{
x[0] = 0, x[1] = \mat{\vec{I}\\ \tdB_0 u[0] }
}{}{of-initial-condition}\\
\OptCons{
\tilde{A} x[T] + \tilde{B} u[T] = 0
}{}{of-boundary-condition} \\
\OptCons{
x[\tau] \in \Scal_x[\tau],\  u[\tau] \in \Scal_u[\tau]
}{}{of-system-level-constraints}
}
where $\tdA$, $\tdB$, and $\tdA_{eq}$ are derived according to the SLS conditions. 

Notice that given $x[\tau]$ as the state and $u[\tau]$ as the control at time $\tau$, \eqn{reformulated_opt} can be seen as a discrete-time state-feedback control problem with state dynamics \eqn{of-state-dynamics}, transition constraint \eqn{of-transition-constraint}, initial condition \eqn{of-initial-condition}, boundary condition \eqn{of-boundary-condition}, and system-level constraints \eqn{of-system-level-constraints}.


\iffalse
Let $x_t = [\Vec{\xx[t]};\ \ \Vec{\xy[t]};\ \ \Vec{\ux[t]}]$ and $U=[\Vec{\uy[t]}]$ where the arrow indicates
flattening the matrix into a vector by transposing and stacking each row. Let $\tilde{A}$ and $\tilde{B}$ be constructed 
such that the first three equations in \eqn{transition} are met. We now have a control problem with initial conditions, 
constraints, and a cost function given by \eqn{reformulated_opt}. By lemma \cite{lem:null-space-is-subspace}, we define $\Xibf_u$ and $\Xibf_x$ such that
\begin{equation}
  \Scal_u[\tau] &= \{ \Pbfxx : \vec{\Pbfxx} \in \null{\Scal_u[\tau]-I} \} 
                &= \{ \Pbfxx : \vec{\Pbfxx} = \Xi_{\Scal_u}[\tau] \hat{v} \}
\end{equation}
\begin{equation}\label{eqn:reformulated_opt}
    \begin{aligned}
    \min_{U \in \mathcal{A}_u} \sum_{\tau=1}^T g(x[\tau],u[\tau]) \\
    \text{s.t. } X(\tau+1) = \tilde{A}x[\tau] + \tilde{B}u[\tau] \\
    x[0] = 0 \\
    \xx[1] = I \\
    \tilde{A}x[T] + \tilde{B}u[T] = 0
    \end{aligned}
\end{equation}

% now we have a control problem with IC, constraints, etc

% discuss what conditions we need
Note that the last condition in \eqn{transition} is unmet; thus we encode it as an 
entrywise linear constraint. Tseng \cite{tseng2020system} illustrates
an implementation of this entrywise linear constraint, and we adopt this formulation for the constraint
\begin{align}
    A \xx[t] + B \ux[t] = \xx[t] A + \xy[t] C
\end{align} 
which, rewritten in vector form, is given by
\begin{align}
    \bar{A}_L x[t] = \bar{A}_R x[t]
\end{align}
and thus $S_x = (\bar{A}_L + I-\bar{A}_R )$. This guarantees that both constraints on $\xx[t]$ are met; see 
Corollary 1 in the next section for more details. \newline

% special case for initialization; need to treat it as two problems because
% the dynamics change
\fi

\subsection{Explicit Solution by Dynamic Programming}
Since \eqn{reformulated_opt} is a state-feedback problem, we can adopt a similar procedure as in \cite{tseng2020system} to solve it. Specifically, we need to 
\begin{itemize}
\item {\it backward recursion:} recursively compute $V_\tau(x[\tau])$ backwards in $\tau$ based on \eqn{of-state-dynamics};
\item {\it transition constraint and boundary condition:} enforce \eqn{of-transition-constraint}, \eqn{of-boundary-condition}, and \eqn{of-system-level-constraints} throughout the derivation.
\item {\it initial condition:} enforce \eqn{of-initial-condition}.
\end{itemize}
In this paper, we show how to derive the DP procedure for unconstrained SLS, i.e., \eqn{reformulated_opt} without system-level constraints \eqn{of-system-level-constraints}, and we could easily extend our results here to handle entrywise linear \eqn{of-system-level-constraints} using similar techniques as in \cite[Section II C]{tseng2020system}.

We examine these three aspects below. 

\paragraph{Backward recursion}
For the backward recursion, we can set
\begin{align*}
f(x[\tau], u[\tau]) = \tdA x[\tau] + \tdB u[\tau]
\end{align*}
and apply the procedure in \sec{preliminaries-DP} to derive $V_\tau(x[\tau])$ and $u[\tau]$. 

\iffalse
For the backward recursion, we can compute $\tdA$ and $\tdB$ by
\begin{align*}
x[\tau + 1] =&\ 
\mat{0 & I}
\mat{
x_{xx}[\tau + 1]\\
x[\tau+1]
}\\ 
=&\ 
\mat{0 & I} \left(
\tilde{A} x[\tau] + \tilde{B} u[\tau] 
\right)\\
=&\ \tdA x[\tau] + \tdB u[\tau] = f(x[\tau], u[\tau]).
\end{align*}
Accordingly, we can directly apply the procedure in \sec{preliminaries-DP} to derive $V_\tau(x[\tau])$ and $u[\tau]$.
\fi

\paragraph{Transition constraint, system constraint, and boundary condition}
We enforce \eqn{of-transition-constraint} and \eqn{of-boundary-condition} during the recursion, which requires maintaining the admissible input set $\Acal_u[\tau]$ as shown in \cite{tseng2020system}. A result in \cite{tseng2020system} iteratively shows that $x[\tau]$ lies in the null space of some matrix $\Psi_x[\tau]$ and derives $\Acal_u[\tau]$ accordingly. 
However, we cannot directly adopt the results from \cite{tseng2020system} to derive $\Acal_u[\tau]$ as we have the new condition \eqn{of-transition-constraint} to meet. 
Fortunately, \cite{tseng2020system} combines its Corollary 1 and equation (11) to deal with additional conditions for $x[\tau]$ (the entrywise linear condition), and we can borrow such a concept to derive the following theorem for our output-feedback scenario to handle the new condition \eqn{of-transition-constraint}.
% By lemma \ref{lem:null-space-is-subspace}, we define $\Xi_{\Scal_u}$ and $\Xi_{\Scal_x}$ such that
% \begin{align*}
%   \Scal_u[\tau] &= \{ \hat{u} : \hat{u} \in \nullspace{(\Scal_u[\tau]-I)} \}  \\
%                 &= \{ \hat{u} : \hat{u}  = \Xi_{\Scal_u}[\tau] \hat{v} \} \\ 
%   \Scal_x[\tau] &= \{ x : x  \in \nullspace{(\Scal_x[\tau]-I)} \}  \\
%                 &= \{ x : x  = \Xi_{\Scal_x}[\tau] \hat{v} \}
% \end{align*}
\begin{theorem}\label{thm:feasible_set_unstable}
  Suppose $x[\tau+1] \in \nul{\Psi_x[\tau+1]}$ for some given matrix $\Psi_x[\tau+1]$. For $\tau \geq 1$, we have 
  \begin{align*}
    \Acal_u[\tau] = \{ \hat{u} : \hat{u} = H_x x[\tau] + H_\lambda \lambda \}
  \end{align*}
  where 
  \begin{align*}
    \Gamma =&\ \mat{-\tdB & \Xi_x[\tau + 1]}, \\
    H_x =&\ \mat{I & 0} \Gamma^+ \tdA, \\
    H_\lambda =&\ \mat{I & 0} (I - \Gamma^+ \Gamma),
  \end{align*}
  and $\Xi_x[\tau+1] = \basis{\nul{\Psi_x[\tau+1]}}$.

  Also, $x[\tau] \in \nul{\Psi_x[\tau]}$ where 
  \begin{align*}
    \Psi_x[\tau] = \mat{
      (\Gamma \Gamma^+ - I)\tdA\\
      \tdA_{eq}
    }.
  \end{align*}
\end{theorem}

\begin{proof}
Without condition \eqn{of-transition-constraint}, the former part follows directly from \cite[Corollary 1]{tseng2020system}. Since \eqn{of-transition-constraint} is equivalent to $x[\tau] \in \nul{\tdA_{eq}}$, the theorem follows from \lem{union-of-null-space}.
\end{proof}

\iffalse
On the other hand, maintaining the satisfactory of \eqn{of-boundary-condition} involves maintaining the admissible input set $\Acal_u[\tau]$ as shown in \cite{tseng2020system}.   since there is a difference between the output-feedback formulation \eqn{reformulated_opt} and the state-feedback formulation in \cite{tseng2020system} -- the condition \eqn{of-state-dynamics} has an additional $x_{xx}[\tau + 1]$ term on the left hand side. Therefore, we need to generalize Theorem 1 in \cite{tseng2020system} to deal with the additional term. To do so, we define $\Upsilon$ such that
\begin{align}
\mat{
x_{xx}[\tau]\\
x[\tau]
} 
= \Upsilon x[\tau] 
= \mat{
I & 0 & 0\\
I & 0 & 0\\
0 & I & 0\\
0 & 0 & I
} 
\mat{
x_{xx}[\tau]\\
x_{xy}[\tau]\\
x_{ux}[\tau]
},
\label{eqn:Upsilon-X}
\end{align}
and we have the following result.

\begin{corollary}\label{cor:feasible_set}
  Suppose $x[\tau+1] \in \nul{\Psi_x[\tau+1]}$ for some given matrix $\Psi_x[\tau+1]$. We have 
  \begin{align*}
    \Acal_u[\tau] = \{ \hat{u} : \hat{u} = H_x x[\tau] + H_\lambda \lambda \}
  \end{align*}
  where 
  \begin{align*}
    \Gamma[\tau] =&\ \mat{-\tilde{B} & \Upsilon \Xi_x[\tau + 1]}, \\
    H_x =&\ \mat{I & 0} \Gamma^+[\tau] \tilde{A}, \\
    H_\lambda =&\ \mat{I & 0} (I - \Gamma^+[\tau] \Gamma[\tau]),
  \end{align*}
  and $\Xi_x[\tau+1]$ is a basis for $\nul{\Psi_x[\tau+1]}$.

  Also, $x[\tau] \in \nul{\Psi_x[\tau]}$ where 
  \begin{align*}
    \Psi_x[\tau] = (\Gamma[\tau] \Gamma^+[\tau] - I)\tilde{A}.
  \end{align*}
\end{corollary}

\begin{proof}
We follow similar strategy as in \cite{tseng2020system}. First we know from \eqn{of-state-dynamics} and \eqn{Upsilon-X} that 
\begin{align*}
\Upsilon x[\tau+1] = \tilde{A} x[\tau] + \tilde{B} u[\tau].
\end{align*}
Since $\Xi_x[\tau+1]$ is a basis for $\nul{\Psi_x[\tau+1]}$ and $x[\tau + 1] \in \nul{\Psi_x[\tau+1]}$, there exists some vector $\theta$ such that
\begin{align*}
\Upsilon x[\tau+1] = \Upsilon \Xi_x[\tau+1] \theta.
\end{align*}
Therefore, 
\begin{align*}
\mat{-\tilde{B} & \Upsilon \Xi_x[\tau+1]} \mat{u[\tau]\\ \theta} = \Gamma[\tau]\mat{u[\tau]\\ \theta} = \tilde{A} x[\tau],
\end{align*}
and the results follow.
\end{proof}
\fi

Using \thm{feasible_set_unstable}, we can define $\Psi_x[T + 1] = I$ and backward-recursively derive each $\Acal_u[\tau]$ and $\Psi_x[\tau]$ to enforce \eqn{of-transition-constraint} and \eqn{of-boundary-condition}. Though \thm{feasible_set_unstable} works in theory, in practice the computation of the pseudo-inverse $\Gamma^+$ can hardly be done precisely. The numerical error then affects the precision of the matrix $\Psi_x$, which further disturbs the resulting basis $\Xi_x$ and causes numerical instability. Therefore, we propose the following theorem that leads to a more numerically stable derivation of $H_x$ and $H_\lambda$.

\begin{theorem}\label{thm:feasible_set}
  Let 
\begin{align*}
\Gamma_A = \Psi_x[\tau+1] \tdA, \quad \Gamma_B = \Psi_x[\tau+1] \tdB.
\end{align*}
  $H_x$ and $H_\lambda$ in \thm{feasible_set_unstable} can be alternatively computed by 
  \begin{align*}
    H_x =&\ \argmin_{M} \norm{\Gamma_B M + \Gamma_A},\\
    H_\lambda =&\ \basis{\nul{\Gamma_B}}.
  \end{align*}
 Also, $x[\tau] \in \nul{\Psi_x[\tau]}$ where 
  \begin{align*}
    \Psi_x[\tau] = \normalize{\mat{
      \Gamma_B H_x + \Gamma_A\\
      \tdA_{eq}
    }}.
  \end{align*}
\end{theorem}

\begin{proof}
Since $x[\tau+1] \in \nul{\Psi_x[\tau+1]}$, we have
\begin{align*}
\Psi_x[\tau+1] x[\tau+1] =&\
\Psi_x[\tau+1] \left(\tdA x[\tau] + \tdB u[\tau] \right) \\
=&\ \Gamma_A x[\tau] + \Gamma_B u[\tau] = 0.
\end{align*}
Therefore, we know 
\begin{align*}
 \Gamma_B u[\tau&] = - \Gamma_A x[\tau]\\
\Rightarrow u[\tau] =&\ - \Gamma_B^+ \Gamma_A x[\tau] + (I - \Gamma_B^+ \Gamma_B) \lambda'\\
=&\ H_x x[\tau] + H_{\lambda'} \lambda'.
\end{align*}
$H_x$ can then be computed by \lem{pinv-equal-regression}. On the other hand, we know $\Gamma_B H_{\lambda'} \lambda' = 0$. Therefore, $H_{\lambda'} \lambda' \in \nul{\Gamma_B}$, and we can reparameterize the space by setting $H_\lambda = \basis{\nul{\Gamma_B}}$. Lastly, the solution to the above equation exists if and only if
\begin{align*}
(- \Gamma_B \Gamma_B^+ \Gamma_A + \Gamma_A) x[\tau] = (\Gamma_B H_x + \Gamma_A) x[\tau] = 0.
\end{align*}
Therefore, $x[\tau] \in \nul{\Gamma_B H_x + \Gamma_A}$. Along with $x[\tau] \in \nul{\tdA_{eq}}$, we can derive $\Psi_x[\tau]$ via \lem{union-of-null-space} and \lem{normalization}.
\end{proof}

\thm{feasible_set} provides a numerically more stable procedure to compute $H_x$ and $H_\lambda$, and while we leave this proof for future work, our experiments indicate that
\begin{itemize}
\item $H_x$ can be computed by regression, which can be done via some sophisticated algorithms;
\item $H_\lambda$ have a smaller dimension;
\item the normalized $\Psi_x$ is less likely to suffer resolution issues. 
\end{itemize}


\iffalse
% subsection 2
%\subsection{Dynamic Programming Phase 1}
% solving first set of equations
When solving each time steps from time $t=T$ to $t=1$, first we determine the set of admissible inputs, $\mathcal{A}_u$. 
This exactly follows Corollary 1 from \cite{tseng2020system}, which we adopt. \newline
% rewrite corollary ADD COROLLARY HERE
\textbf{Corollary 1.} \textit{Suppose $x[\tau+1]\in \nullspace(\Psi_x[\tau+1])$ for some
given matrix $\Psi_x[\tau+1]$, we have}
\begin{equation*}
    \mathcal{A}_v[\tau] = \{ \hat{v} : \hat{v} = H_xx[\tau]+H_{\lambda}\lambda
\end{equation*}
where
\begin{align*}
    \begin{gathered}
        \Gamma[\tau] = \begin{bmatrix}
            -\tilde{B}\Xi_{S_u}[\tau]  &\Xi_x[\tau+1]
            \end{bmatrix}, \\
            H_x = [I\ 0] \Gamma^+[\tau]\tilde{A}, \\
            H_{\lambda} = [I\ 0](I -\Gamma^+[\tau]\Gamma[\tau]),
    \end{gathered}
\end{align*}
\textit{and $\Xi_x[\tau+1]$ is given by }
\begin{equation}
    \Xi_x[\tau+1] = \nullspace \Psi_x[\tau+1] = \nullspace 
        \begin{bmatrix}
        S_x[\tau] - I \\ \Omega[\tau]
        \end{bmatrix}  
\end{equation}
 
\textit{Also,
$x[\tau]\in \nullspace(\Omega[\tau])$ where}
\begin{equation*}
    \Omega[\tau] = (\Gamma[\tau]\Gamma^+[\tau]-I)\tilde{A}.
\end{equation*}
Once we obtain the set of admissible inputs, we consider the cost-to-to function, which we seek to minimize. We define 
the cost-to-go function recursively, dependent on the cost-to-go at the next time step.
\begin{equation*}\label{eqn:cost_to_go_phase1}
    \begin{aligned}
            V_{\tau}(x[\tau]) = \min_{\hat{u} \in \mathcal{A}_u} g(x[\tau],u[\tau]) + V_{\tau+1}(\tilde{A}x[\tau]+\tilde{B}u[\tau]) \\
    \end{aligned}
\end{equation*}
Accordingly, the control input is given by
\begin{equation*}\label{eqn:control_phase1}
    u[\tau] = \argmin_{\hat{u} \in \mathcal{A}_u} g(x[\tau],u[\tau]) + V_{\tau+1}(\tilde{A}x[\tau]+\tilde{B}u[\tau]). \\
\end{equation*}
Given these two definitions, we then solve for $U_t$.
\fi


\paragraph{Initial condition} Under the state-feedback scenario in \cite{tseng2020system}, we only need to set $\Pxx[1] = I$ at the end to enforce the initial condition. However, under our output-feedback setting, we have two sets of initial conditions. We need to ensure both $x[0]$ and $x[1]$ in \eqn{of-initial-condition}. Therefore, we partition the whole backward recursion into two phases: from $T$ to $1$ and from $1$ to $0$. For the former phase, we derive $\Acal_u[\tau]$ and $\Psi_x[\tau]$ recursively according to \thm{feasible_set} until we obtain $\Psi_x[1]$. In the next phase, we derive $\Acal_u[0]$ using the following theorem.

\begin{theorem}\label{thm:feasible_set0}
  Suppose $x[1] \in \nul{\Psi_x[1]}$ for some given matrix $\Psi_x[1]$ where
  $
  \Psi_x[1] = \mat{ \Psi_{x_1}[1] & \Psi_{x_2}[1] }
  $
  such that 
  \begin{align*}
  \Psi_{x_1}[1] x_{xx}[1] + \Psi_{x_2}[1] \mat{x_{xy}[1] \\ x_{ux}[1]} = 0.
  \end{align*}
   We have
  \begin{align*}
    \Acal_u[0] = \{ \hat{u} : \hat{u} = w + H_\lambda \lambda \}
  \end{align*}
  where 
  \begin{align*}
    \Gamma =&\ \Psi_{x_2}[1] \tdB_0, \\ 
    w =&\ \argmin_{M} \norm{\Gamma + \Psi_{x_1}[1] \vec{I}}, \\
    H_\lambda =&\ \basis{\nul{\Gamma}}.
  \end{align*}
\end{theorem}

\begin{proof}
Since $x[1] \in \nul{\Psi_x[1]}$, we have 
\begin{align*}
\Psi_x[1] x[1] = 0 
=&\ \Psi_x[1] \mat{\vec{I}\\ \tdB_0 u[0] }\\
=&\ \Psi_{x_1}[1] \vec{I} + \Psi_{x_2}[1] \tdB_0 u[0].
\end{align*}
Rearrange the terms and we obtain
\begin{align*}
 \Psi_{x_2}[1] \tdB_0 u[0] = \Gamma u[0] = - \Psi_{x_1}[1] \vec{I}.
\end{align*}
Therefore,
\begin{align*}
u[0] = - \Gamma^+ \Psi_{x_1}[1] \vec{I} + (I - \Gamma^+\Gamma) \lambda.
\end{align*}
We can then show the results following the same procedure in the proof of \thm{feasible_set}.
\end{proof}

Combining both \thm{feasible_set} and \thm{feasible_set0}, we can derive admissible input sets $\Acal_u[\tau]$ for all $\tau = 0, \dots, T$. Let $\unvec{x}$ rebuild a matrix $A$ such that $\vec{A} = x$, we present our DP output-feedback SLS in \alg{plainSLS}.


\iffalse
% subsection 3
%\subsection{Dynamic Programming Phase 2}
The cost-to-go function takes a different form at time $t=0$. Because the constraints in \eqn{transition} do not hold 
between $\tau=0$ and $\tau=1$, and because $x[1]$ is partially prespecified
by the constraint $\xx[1]=I$, a different cost-to-go function is needed for the initial state. Define $\bar{B}$ to be the 
matrix encoding multiplication of $\Vec{\uy}$ by $B$ and $C$ on the left and right respectively. The cost-to-go and the corresponding
control input are given in \eqn{cost_to_go0}.
\begin{equation}\label{eqn:cost_to_go0}
    \begin{aligned}
            V_{0}(x[0]) = \min_{\hat{u} \in \mathcal{A}_u} g(x[0],u[0]) + V_{1}([\Vec{I};\Bar{B}u[0]]) \\
            u[0] = \argmin_{\hat{u} \in \mathcal{A}_u} g(x[0],u[0]) + V_{1}([\Vec{I};\Bar{B}u[0]])
    \end{aligned}
\end{equation}
Note that the set of admissible inputs, $\mathcal{A}_u$, cannot be determined by Corollary 1 from \cite{tseng2020system} for the $\tau=0$ case
because the cost function changes. We have some $\Psi_x[1]$ from the previous time step, and we require that $x[1] \in \nullspace \Psi_x[1]$.
Thus $\Psi_x[1]x[1] = \Psi_x[1][\Vec{I};\Bar{B}u[\tau]] = 0$. Splitting $\Psi_x[1]$ into two submatrices as
\begin{align*}
    \Psi_x[1] = \begin{bmatrix}
        \Psi_{x_1} \\
        \Psi_{x_2}
    \end{bmatrix}
\end{align*}
we can rewrite the equation as 
\begin{align*}
    \Psi_{x_1}\Vec{I} + \Psi_{x_2} \Bar{B}u[\tau] = 0.
\end{align*}
In the case where $\Gamma = \Psi_{x_2} \Bar{B}$ is nonzero, $u[\tau]$ is parameterized by $\lambda$ as shown in \eqn{parameterized_Au}.
\begin{align}\label{eqn:parameterized_Au}
    u[\tau] = H_{\lambda}\lambda + w \\
    \nonumber \text{where} \\
    \nonumber \Gamma = \Psi_{x_2} \Bar{B} \\
    \nonumber H_{\lambda} = I - \Gamma^+\Gamma \\
    \nonumber w = -\Gamma^+\Psi_{x_1}\Bar{B}
\end{align}
Because no future control inputs are needed, we do not need to compute $\Psi_x[0]$. With the form of $u[0]$ determined,
we can solve \eqn{cost_to_go0} for $u[0]$. The steps are summarized in algorithm \ref{algo:plainSLS}.
\fi


\begin{algorithm}
\caption{DP for output feedback SLS}\label{alg:plainSLS}
\begin{algorithmic}[1]
    \REQUIRE Per-step costs $g_{\tau}(\Pxx[\tau],\Pxy[\tau],\Pux[\tau],\Puy[\tau])$ for all $\tau = 0, \dots, T$ and the matrices $A$, $B$, and $C$ in \eqn{SLS_output_feedback}.
    \ENSURE $\Pxx[\tau],\Pxy[\tau],\Pux[\tau],\Puy[\tau]$ for all $\tau = 0, \dots, T$.
    \STATE Derive $h_\tau$ from $g_{\tau}$ for all $\tau = 0, \dots, T$.\label{plainSLS-setup0}
    \STATE Derive $\tdA$, $\tdB$, $\tdA_{eq}$, and $\tdB_0$ from $A$, $B$ and $C$ according to \eqn{SLS_output_feedback}.
    \STATE $\Psi_x[T+1] = I$.
    \STATE $V_{T+1}(x[T+1]) = 0$.\label{plainSLS-setup1}
    \FOR{$\tau=T,\dots,1$}
        \STATE Derive $\Acal_u[\tau]$ and $\Psi_x[\tau]$ by \thm{feasible_set}.\label{plainSLS-compute0}
        \STATE Compute $K_{\tau}(x[\tau])$ by \eqn{DP-U}.
        \STATE Derive $V_{\tau}(x_{\tau})$ by \eqn{DP-cost-to-go}.\label{plainSLS-compute1}
    \ENDFOR
    \STATE Derive $\Acal_u[0]$ by \thm{feasible_set0}.\label{plainSLS-final0}
    \STATE Compute $u[0]$ by \eqn{DP-U}.
	\STATE Set $\Puy[0] = \unvec{u[0]}$ and $\Pxx[0] = \Pxy[0] = \Pux[0] = 0$.
    \STATE Compute $x[1]$ by \eqn{of-initial-condition}.    
    \FOR{$\tau=1,\dots,T$}\label{plainSLS-final0.0}
        \STATE $u[\tau] = K_{\tau}(x[\tau]).$
        \STATE Set $\Pxx[\tau] = \unvec{x_{xx}[\tau]}$, $\Pxy[\tau] = \unvec{x_{xy}[\tau]}$, $\Pux[\tau] = \unvec{x_{ux}[\tau]}$, and $\Puy[\tau] = \unvec{u[\tau]}$.
		\STATE $x[\tau+1] = \tdA x[\tau] + \tdB u[\tau]$.        
    \ENDFOR\label{plainSLS-final1}
\end{algorithmic}
\end{algorithm}

% solving second set

% In the case of output feedback, we can write the transfer function constraints as \newline
% \textit{Initial Conditions}
% \begin{align}
%     \begin{gathered}
%     \xx[0] = 0 \\
%     \xx[1] = I \\
%     \xy[0] = 0 \\
%     \ux[0] = 0 \\
%     \end{gathered}
% \end{align}\label{eqn:initialconditions}
% \textit{Transition Conditions}
% \begin{align}\label{eqn:transition}
%     \xx[t+1] &= A \xx[t] + B \ux[t] & \text{for } & t \in [1,T] \\
%     \xy[t+1] &= A \xy[t] + B \uy[t] & \text{for } & t \in [0,T]\\
%     \ux[t+1] &= \ux[t] A + \uy[t] C & \text{for } & t \in [0,T]\\
%     \xx[t+1] &= \xx[t] A + \xy[t] C & \text{for } & t \in [1,T]\\
% \end{align}
% \textit{Terminal Conditions}
% \begin{align}
%     \begin{gathered}
%     A \xx[T] + B \ux[T] = 0 \\
%     A \xy[T] + B \uy[T] = 0 \\
%     \ux[T] A + \uy[T] C = 0 \\
%     \xx[T] A + \xy[T] C = 0 \\
%     \end{gathered}\label{eqn:termination}
% \end{align}

% don't define size of X, just define how we flatten X / U

% explain each equation, at least a few comments


\subsection{Approximation for Faster Computation}
Though \thm{feasible_set} has greatly improved the numerical stability and simplified computation over \thm{feasible_set_unstable}, calculating the matrices in \thm{feasible_set} is still computationally expensive. Therefore, we explore the possibility of an approximation algorithm which trades the precision for faster computation. Inspired by the approximation to the infinite horizon SLS problem
in \cite{tseng2020system}, we can relax \eqn{of-transition-constraint} and \eqn{of-boundary-condition} by using
\begin{align*}
H_x = 0, \quad H_\lambda = I,
\end{align*}
which is equivalent to an unconstrained $\Acal_u$, and reuse $\Psi_x[T_a]$ as $\Psi_x[1]$ for 
\thm{feasible_set0} where $T_a$ is the \emph{allowance}, that is, the number of time steps at which we use
an unconstrained $\Acal_u$. We summarize this approximation in \alg{approxDP}. We observe imperically that the null space defining $\Acal_u$ is close enough to $\Rmbb^n$ that it is practically useful; we defer proof of this to future work.

\iffalse
The nullspace operation in Corollary 1 is computationally expensive, so we develop an approximation algorithm that
reduces the number of times the nullspace is used. Inspired by the approximation to the infinite horizon SLS problem
in \cite{tseng2020system}, we approximate $\nullspace \Psi_x[t]$ by "reusing" the set $\bar{\mathcal{A}_u}$
for times $t<T$. The set $\bar{\mathcal{A}_u}$ is computed using Corollary 1, with $\Psi_x=S_x-I$. Thus
the only constraint we place on the set of admissible inputs is that $\uy[t]$ will ensure that $\xx[t+1]=\xx[t]A+\xy[t]C$. 
This in turn relaxes the constraint that $\xy[T+1]=\xx[T+1]=\ux[T+1]=0$; our results show that this condition is still met 
even without the formal guarantee. The steps are summarized in algorithm \ref{alg:approxDP}.
\fi 

\begin{algorithm}
\caption{DP Approximation for output feedback SLS}\label{alg:approxDP}
\begin{algorithmic}[1]
    \REQUIRE Per-step costs $g_{\tau}(\Pxx[\tau],\Pxy[\tau],\Pux[\tau],\Puy[\tau])$ for all $\tau = 0, \dots, T$, the matrices $A$, $B$, and $C$ in \eqn{SLS_output_feedback}, and allowance $T_a$.
    \ENSURE $\Pxx[\tau],\Pxy[\tau],\Pux[\tau],\Puy[\tau]$ for all $\tau = 0, \dots, T$.
    \STATE Follow line \ref{plainSLS-setup0} to \ref{plainSLS-setup1} in \alg{plainSLS}.
    \FOR{$\tau=T,\dots,T_a$}
        \STATE Perform line \ref{plainSLS-compute0} to \ref{plainSLS-compute1} in \alg{plainSLS}.
    \ENDFOR
	
    \FOR{$\tau=T_a,\dots,1$}
        \STATE Compute $K_{\tau}(x[\tau])$ by \eqn{DP-U} with unconstrained $\Acal_u[\tau]$.
        \STATE Derive $V_{\tau}(x_{\tau})$ by \eqn{DP-cost-to-go}.
    \ENDFOR
    \STATE Let $\Psi_x[1] = \Psi_x[T_a]$.
    \STATE Perform line \ref{plainSLS-final0} to \ref{plainSLS-final1} in \alg{plainSLS}.
\end{algorithmic}
\end{algorithm}